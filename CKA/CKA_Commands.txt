
Important commands for Kubernetes:

To run a Pod :

	kubectl run <podname> --image=<Imagename>
  
To run a deployment :

	kubectl create deployment <name> --image=<imagename> --replicas=<no>



To Taint a Node :
	
	kubectl taint node <nodeName> <key>=<value>:<taint-effect>
												
												taint-effect = NoSchedule| PreferNoSchedule | NoExecute
	
	ex: kubectl taint node node01 app=frontEnd:NoSchedule
	
To remove Taint on a Node :

	Add - at the end of taint command
    kubectl taint node <nodeName> <key>=<value>:<taint-effect>-
	
Add Toleration to a Pod:
	
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  tolerations:
  - key: "key1"
    operator: "Equal"
	value:"value1"
    effect: "NoSchedule"
	

 Problem with taint and tolerations is it doesnot guarantee that the pod will be placed on a specific node.
 
 Placing pod on a specific Node :
 
 1)Using Node name :
	Using "nodeName" in pod  spec tag.
 
 2) Using Node Selectors : For this we need to label the nodes.
	
	Creating labels for a Node
	
	kubectl label node <NodeName> <key>=<value>
	Ex: kubectl label nodes node-1 size=Large
	
	Using Node selector in a pod
	
	apiVersion	: V1
	kind : Pod
	metadata:
	 name:myapp-pod
	spec:
	 nodeSelector :
		size:Large
		
	Limitaion with node selector we can add only one condition .We cannot multiple conditions add like size: large or size:medium

3) Using Node Affinity : 
	Creating labels for a Node
	
	kubectl label node <NodeName> <key>=<value>
	Ex: kubectl label nodes node-1 size=Large
	
	
	Add node Affinity
	==================
	apiVersion: v1
	kind: Pod
	metadata:
		name: with-node-affinity
	spec:
	 containers:
	  - name: nginx
	    image: nginx 
	 affinity:
	  nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: size
              operator: In
              values:
              - Large
			  - medium
	
	
	Supported Operators:
	In, NotIn, Exists and DoesNotExist 
	

DaemonSets :

	This will be create a pod when a new node is created.
	
	To get the daemon set
	Ex: kubectl get daemonset;
	
	To create a daemon set ( this is like creating a replicaset)  excpet the type is DaemonSet
  
	apiVersion: apps/v1
	kind: DaemonSet
	metadata:
		name: fluentd-elasticsearch
   
	
Static pods :

	Kubelet will store the pod definiton file in --pod-manifestpath="etc/kubernets/manifests" folder or --condif prop.
	This directory is passed as an argument while creating the kublet service.
	Placing pod definiton file here will allow the kubelet to create the pod.
	
	find the static pods in all namespaces
	 kubectl get pods -A ( find the pods  name which ends with naode name etc)
	 or 
	 check the owner section in pod yaml where owner reference kind=node
	   ownerReferences:
		  - apiVersion: v1
			controller: true
			kind: Node
			name: controlplane
			
	for non static pods kind: ReplicaSet
	 ownerReferences:
	  - apiVersion: apps/v1
		blockOwnerDeletion: true
		controller: true
		kind: ReplicaSet
			
	How many pod definition files are present in the manifests folder?
	
	cd /etc/kubernetes/manifests ➜  ls
	etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml
	
	ssh to the node on which pods is avialble
	Satic pods exists at /etc/kubernetes/manifests 
	
	If not availble check the config file in  “var/lib/kublet/config.yaml” and check the static pod path 
	staticPodPath: /etc/just-to-mess-with-you
	
Configure Custom Scheduler :

  If  scheduler configured using service then check the --config in service	
  kube-scheduler.service
  ======================
	Default Scheduler :
	====================
	wget https://storage.googleapis.com/kubernetes-release/release/v1.12.0/bin/linux/amd64/kube-scheduler
	ExecStart=/usr/local/bin/kube-scheduler \\
	--config=/etc/kubernetes/config/kube-scheduler.yaml \\
	--scheduler-name= default-scheduler
	ExecStart=/usr/local/bin/kube-scheduler \\
	
	Custome Scheduler:
	=================
	--config=/etc/kubernetes/config/kube-scheduler.yaml \\
	my-custom-scheduler.service
	--scheduler-name= my-custom-scheduler
	
  If scheduler configured using static pods in static pods location change the scheduler.yaml file


Metrics  :

  Install metrics server to get the node/pod metrics.
  
  Minikube : minikube addons enable metrics-server
  Other clusters : 
	git clone https://github.com/kubernetes-incubator/metrics-server.git
	kubectl create –f deploy/1.8+/
		others
		clusterrolebinding "metrics-server:system:auth-delegator" created
		rolebinding "metrics-server-auth-reader" created
		apiservice "v1beta1.metrics.k8s.io" created
		serviceaccount "metrics-server" created
		deployment "metrics-server" created
		service "metrics-server" created
		clusterrole "system:metrics-server" created
		clusterrolebinding "system:metrics-server" created
		
		
  Node metrics : kubectl top node
  Pod metrics : kubectl top pod
  
  logs : 
  
	Display logs in a container
	
	kubectl logs –f  <POD_NAME> <CONTAINER_NAME>
	kubectl logs –f event-simulator-pod event-simulator
	
Deployment Strategies :

	1) Recreate
	2) Rolling updates - ( Default )
	
	Every deployment will have rollouts and versions
	
	>kubectl rollout status deployment/ myapp-deployment
	
	>kubectl rollout history deployment/ myapp deployment
	deployments "
	myapp deployment"
	REVISION CHANGE
	CAUSE
	1 <none>
	2 kubectl apply filename=deployment definition.yml record=true

Rolling Updates :

	Create deployment with nginx:1.8
	 >kubectl create -f nginx-deployment.yaml ( nginx:1.8)
	Change the version to nginx:1.9.1 in nginx-deployment.yaml file
	 >kubectl apply -f nginx-deployment.yaml
	or
	 >kubectl set image deployment/myapp_deployment nginx =nginx:1.9.1
		

	Deployement will create a replcaset with specific version
	When a new verison is deployed a new version of replicaset is created with in deployment.

	To rollback to prev deployment version 
	 >kubectl rollout undo deployment/ myapp deployment
 
	
	
	
	
 

